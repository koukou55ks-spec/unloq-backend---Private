"""
é«˜é€ŸåŒ–ã•ã‚ŒãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ç‰ˆ
"""

import asyncio
import json
import time
from datetime import datetime
from typing import Dict, List, Any, Optional
import google.generativeai as genai
from concurrent.futures import ThreadPoolExecutor

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
from dotenv import load_dotenv
load_dotenv()

class FastChatbot:
    """é«˜é€ŸåŒ–ã•ã‚ŒãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ"""
    
    def __init__(self):
        self._initialize_gemini()
        self.executor = ThreadPoolExecutor(max_workers=3)
        self.cache = {}
        self.cache_ttl = 300  # 5åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        
    def _initialize_gemini(self):
        """Gemini APIã®åˆæœŸåŒ–"""
        try:
            import os
            api_key = os.getenv("GEMINI_API_KEY")
            if api_key:
                genai.configure(api_key=api_key)
                self.model = genai.GenerativeModel('gemini-2.0-flash-exp')
                print("ğŸš€ é«˜é€ŸGemini APIãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ")
            else:
                self.model = None
                print("âš ï¸ Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        except Exception as e:
            print(f"âŒ GeminiåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            self.model = None
    
    def _get_cache_key(self, query: str, user_id: str) -> str:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆ"""
        return f"{user_id}:{hash(query.lower().strip())}"
    
    def _is_cache_valid(self, timestamp: float) -> bool:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæœ‰åŠ¹ã‹ãƒã‚§ãƒƒã‚¯"""
        return time.time() - timestamp < self.cache_ttl
    
    async def process_query_fast(self, query: str, user_id: str = "anonymous") -> Dict[str, Any]:
        """
        é«˜é€Ÿã‚¯ã‚¨ãƒªå‡¦ç†
        """
        start_time = time.time()
        
        try:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
            cache_key = self._get_cache_key(query, user_id)
            if cache_key in self.cache:
                cached_data = self.cache[cache_key]
                if self._is_cache_valid(cached_data['timestamp']):
                    cached_data['response_time'] = time.time() - start_time
                    cached_data['from_cache'] = True
                    return cached_data
            
            # ä¸¦åˆ—å‡¦ç†ã§AIå›ç­”ã¨åŸºæœ¬æƒ…å ±ã‚’å–å¾—
            tasks = [
                self._generate_ai_response(query),
                self._get_basic_context(query)
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            ai_response = results[0] if not isinstance(results[0], Exception) else "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚å›ç­”ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"
            context = results[1] if not isinstance(results[1], Exception) else {}
            
            # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            confidence_score = self._calculate_confidence(query, ai_response)
            
            response_time = time.time() - start_time
            
            result = {
                "answer": ai_response,
                "confidence_score": confidence_score,
                "response_time": response_time,
                "context": context,
                "timestamp": datetime.now().isoformat(),
                "from_cache": False
            }
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            self.cache[cache_key] = {
                **result,
                'timestamp': time.time()
            }
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºåˆ¶é™ï¼ˆæœ€å¤§100ã‚¨ãƒ³ãƒˆãƒªï¼‰
            if len(self.cache) > 100:
                oldest_key = min(self.cache.keys(), key=lambda k: self.cache[k]['timestamp'])
                del self.cache[oldest_key]
            
            return result
            
        except Exception as e:
            print(f"âŒ é«˜é€Ÿå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "answer": "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚",
                "confidence_score": 0.0,
                "response_time": time.time() - start_time,
                "context": {},
                "timestamp": datetime.now().isoformat(),
                "error": str(e)
            }
    
    async def _generate_ai_response(self, query: str) -> str:
        """AIå›ç­”ã‚’ç”Ÿæˆï¼ˆéåŒæœŸï¼‰"""
        if not self.model:
            print("âš ï¸ Geminiãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å›ç­”ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            return self._get_fallback_response(query)
        
        try:
            print(f"ğŸ¤– Gemini APIã§å›ç­”ç”Ÿæˆä¸­: {query[:50]}...")
            
            # ç°¡æ½”ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§é«˜é€ŸåŒ–
            prompt = f"""
ã‚ãªãŸã¯çŸ¥è­˜è±Šå¯ŒãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®è³ªå•ã«å¯¾ã—ã¦ã€ç°¡æ½”ã§åˆ†ã‹ã‚Šã‚„ã™ã„å›ç­”ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

è³ªå•: {query}

å›ç­”ã¯ä»¥ä¸‹ã®å½¢å¼ã§æä¾›ã—ã¦ãã ã•ã„ï¼š
- è¦ç‚¹ã‚’3ã¤ä»¥å†…ã«ã¾ã¨ã‚ã‚‹
- å…·ä½“çš„ã§å®Ÿç”¨çš„ãªæƒ…å ±ã‚’å«ã‚ã‚‹
- æ—¥æœ¬èªã§å›ç­”ã™ã‚‹
"""
            
            # éåŒæœŸã§Gemini APIã‚’å‘¼ã³å‡ºã—
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                self.executor,
                lambda: self.model.generate_content(
                    prompt,
                    generation_config=genai.types.GenerationConfig(
                        temperature=0.7,
                        max_output_tokens=500,  # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’åˆ¶é™ã—ã¦é«˜é€ŸåŒ–
                        top_p=0.8,
                        top_k=40
                    )
                )
            )
            
            if response and response.text:
                print(f"âœ… Geminiå›ç­”ç”ŸæˆæˆåŠŸ: {len(response.text)}æ–‡å­—")
                return response.text
            else:
                print("âš ï¸ Geminiã‹ã‚‰ç©ºã®å›ç­”ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½¿ç”¨ã€‚")
                return self._get_fallback_response(query)
            
        except Exception as e:
            print(f"âš ï¸ AIå›ç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return self._get_fallback_response(query)
    
    async def _get_basic_context(self, query: str) -> Dict[str, Any]:
        """åŸºæœ¬çš„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’å–å¾—ï¼ˆè»½é‡ç‰ˆï¼‰"""
        try:
            # è»½é‡ãªå‡¦ç†ã®ã¿å®Ÿè¡Œ
            context = {
                "query_type": self._classify_query_type(query),
                "keywords": self._extract_keywords(query),
                "timestamp": datetime.now().isoformat()
            }
            return context
        except Exception as e:
            print(f"âš ï¸ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _classify_query_type(self, query: str) -> str:
        """ã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ—ã‚’åˆ†é¡"""
        query_lower = query.lower()
        
        if any(word in query_lower for word in ['ç¨é‡‘', 'ç¨å‹™', 'ç¢ºå®šç”³å‘Š', 'æ§é™¤']):
            return "ç¨å‹™"
        elif any(word in query_lower for word in ['æŠ•è³‡', 'è³‡ç”£', 'è²¯è“„', 'é‡‘è']):
            return "æŠ•è³‡ãƒ»è³‡ç”£"
        elif any(word in query_lower for word in ['å­¦ç¿’', 'å‹‰å¼·', 'æ•™ãˆã¦', 'èª¬æ˜']):
            return "å­¦ç¿’ãƒ»æ•™è‚²"
        else:
            return "ä¸€èˆ¬"
    
    def _extract_keywords(self, query: str) -> List[str]:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        # ç°¡å˜ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        import re
        words = re.findall(r'\b\w+\b', query)
        # é•·ã•ãŒ2æ–‡å­—ä»¥ä¸Šã®å˜èªã®ã¿æŠ½å‡º
        keywords = [word for word in words if len(word) >= 2]
        return keywords[:5]  # æœ€å¤§5å€‹ã¾ã§
    
    def _calculate_confidence(self, query: str, response: str) -> float:
        """ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        try:
            # ç°¡å˜ãªä¿¡é ¼åº¦è¨ˆç®—
            if not response or "ã‚¨ãƒ©ãƒ¼" in response or "ç”³ã—è¨³" in response:
                return 0.3
            
            # å›ç­”ã®é•·ã•ã¨å†…å®¹ã§åˆ¤å®š
            if len(response) > 50 and len(response) < 1000:
                return 0.8
            elif len(response) >= 20:
                return 0.6
            else:
                return 0.4
                
        except Exception:
            return 0.5
    
    def _get_fallback_response(self, query: str) -> str:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å›ç­”ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
        query_lower = query.lower()
        
        # ã‚ˆã‚Šå…·ä½“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
        if any(word in query_lower for word in ['ç¨é‡‘', 'ç¨å‹™', 'ç¢ºå®šç”³å‘Š', 'æ§é™¤', 'æ‰€å¾—ç¨', 'ä½æ°‘ç¨']):
            return """
ğŸ“Š **ç¨å‹™ã«é–¢ã™ã‚‹ã”è³ªå•**

**ä¸»ãªãƒã‚¤ãƒ³ãƒˆï¼š**
â€¢ ç¢ºå®šç”³å‘Šã¯æ¯å¹´2æœˆ16æ—¥ã€œ3æœˆ15æ—¥
â€¢ çµ¦ä¸æ‰€å¾—æ§é™¤ã€åŸºç¤æ§é™¤ãªã©ã®å„ç¨®æ§é™¤ã‚’æ´»ç”¨
â€¢ åŒ»ç™‚è²»æ§é™¤ã€ãµã‚‹ã•ã¨ç´ç¨ãªã©ã§ç¯€ç¨å¯èƒ½

**è©³ç´°æƒ…å ±ãŒå¿…è¦ã§ã—ãŸã‚‰ã€å…·ä½“çš„ãªçŠ¶æ³ã‚’ãŠèã‹ã›ãã ã•ã„ã€‚**
"""
        
        elif any(word in query_lower for word in ['æŠ•è³‡', 'è³‡ç”£', 'è²¯è“„', 'é‡‘è', 'æ ªå¼', 'nisa']):
            return """
ğŸ’° **æŠ•è³‡ãƒ»è³‡ç”£ã«é–¢ã™ã‚‹ã”è³ªå•**

**åŸºæœ¬åŸå‰‡ï¼š**
â€¢ åˆ†æ•£æŠ•è³‡ã§ãƒªã‚¹ã‚¯ã‚’è»½æ¸›
â€¢ é•·æœŸæŠ•è³‡ã§è¤‡åˆ©åŠ¹æœã‚’æ´»ç”¨
â€¢ NISAãƒ»iDeCoãªã©ã®ç¨åˆ¶å„ªé‡åˆ¶åº¦ã‚’åˆ©ç”¨

**å€‹åˆ¥ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã«ã¯ã€æŠ•è³‡ç›®æ¨™ã‚„æœŸé–“ã®è©³ç´°ãŒå¿…è¦ã§ã™ã€‚**
"""
        
        elif any(word in query_lower for word in ['ã‚¢ãƒ«ãƒã‚¤ãƒˆ', 'ãƒã‚¤ãƒˆ', 'å‰¯æ¥­', 'åå…¥', 'çµ¦ä¸']):
            return """
ğŸ’¼ **ã‚¢ãƒ«ãƒã‚¤ãƒˆãƒ»åå…¥ã«é–¢ã™ã‚‹ã”è³ªå•**

**é‡è¦ãªãƒã‚¤ãƒ³ãƒˆï¼š**
â€¢ å¹´å103ä¸‡å††ä»¥ä¸‹ãªã‚‰æ‰€å¾—ç¨éèª²ç¨
â€¢ 130ä¸‡å††ã‚’è¶…ãˆã‚‹ã¨ç¤¾ä¼šä¿é™ºã®æ‰¶é¤Šã‹ã‚‰å¤–ã‚Œã‚‹
â€¢ å‰¯æ¥­åå…¥ã¯20ä¸‡å††ã‚’è¶…ãˆã‚‹ã¨ç¢ºå®šç”³å‘ŠãŒå¿…è¦

**å…·ä½“çš„ãªçŠ¶æ³ã‚’ãŠèã‹ã›ã„ãŸã ã‘ã‚Œã°ã€è©³ã—ãã‚¢ãƒ‰ãƒã‚¤ã‚¹ã§ãã¾ã™ã€‚**
"""
        
        else:
            return f"""
ğŸ¤– **ã”è³ªå•ã€Œ{query[:30]}...ã€ã«ã¤ã„ã¦**

ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç¾åœ¨AIã‚·ã‚¹ãƒ†ãƒ ãŒä¸€æ™‚çš„ã«åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚

**ä»£æ›¿æ¡ˆï¼š**
â€¢ ã‚ˆã‚Šå…·ä½“çš„ãªè³ªå•ã§å†åº¦ãŠè©¦ã—ãã ã•ã„
â€¢ ç¨å‹™ã€æŠ•è³‡ã€ã‚¢ãƒ«ãƒã‚¤ãƒˆãªã©ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚ã¦ãã ã•ã„
â€¢ ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„

**ãŠå½¹ã«ç«‹ã¦ã‚‹ã‚ˆã†æ”¹å–„ã«åŠªã‚ã¦ãŠã‚Šã¾ã™ã€‚**
"""
    
    def clear_cache(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        self.cache.clear()
        print("ğŸ§¹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆã‚’å–å¾—"""
        return {
            "cache_size": len(self.cache),
            "cache_limit": 100,
            "ttl_seconds": self.cache_ttl
        }

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
fast_chatbot = FastChatbot()
